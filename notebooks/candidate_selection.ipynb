{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook makes the files necessary for candidate selection.\n",
    "\n",
    "Final candidate selection will be combining LSH candidates with anchor text candidates. Final candidate selection function is stored in candidate_selection.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import re\n",
    "import unidecode\n",
    "from collections import defaultdict\n",
    "from nltk import ngrams\n",
    "from tqdm import tqdm_notebook\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasketch import MinHash, MinHashLSHForest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wikidata \n",
    "wikidata = pd.read_csv('../data/wikipages_cleaned.csv')\n",
    "wikidata = wikidata.dropna()\n",
    "#Unfortunately can't put all pages in LSH due to memory constraints\n",
    "top_wikidata = wikidata.sort_values(by = 'views', ascending = False).iloc[:4000000]\n",
    "top_wikidata.to_csv('../data/candidate_selection/top_wikipages.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess(text):\n",
    "    #Substitute non-alphanumeric characters with _\n",
    "    text = re.sub(r'[^\\w]','_',text)\n",
    "    #Lower case everything character\n",
    "    text = text.lower()\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#https://www.learndatasci.com/tutorials/building-recommendation-engine-locality-sensitive-hashing-lsh-python/\n",
    "#Make LSH\n",
    "#Number of Permutations\n",
    "permutations = 128\n",
    "def get_forest(data, perms):    \n",
    "    minhash = []\n",
    "    for text in tqdm_notebook(data['page_title'], total = len(data)):\n",
    "        text_preprocessed = preprocess(text)\n",
    "        m = MinHash(num_perm=perms)\n",
    "        for d in ngrams(text_preprocessed, 3):\n",
    "            m.update(\"\".join(d).encode('utf-8'))\n",
    "        minhash.append(m)    \n",
    "    forest = MinHashLSHForest(num_perm=perms)\n",
    "    for i,m in enumerate(tqdm_notebook(minhash)):\n",
    "        forest.add(i,m)\n",
    "        \n",
    "    forest.index()\n",
    "    return forest\n",
    "forest = get_forest(top_wikidata, permutations)\n",
    "with open('../data/candidate_selection/lsh_forest.pkl', 'wb') as f:\n",
    "    pickle.dump(forest, f)\n",
    "\n",
    "\n",
    "\n",
    "def predict(text, database, perms, num_results, forest):    \n",
    "    text_preprocessed = preprocess(text)\n",
    "    m = MinHash(num_perm=perms)\n",
    "    for d in ngrams(text_preprocessed, 3):\n",
    "        m.update(\"\".join(d).encode('utf-8'))\n",
    "    idx_array = np.array(forest.query(m, num_results))\n",
    "    if len(idx_array) == 0:\n",
    "        return None # if your query is empty, return none\n",
    "    \n",
    "    result = database.iloc[idx_array]['wikidata_numeric_id'].astype(int)    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anchor_text</th>\n",
       "      <th>target_page_id</th>\n",
       "      <th>target_wikidata_numeric_id</th>\n",
       "      <th>anchor_target_count</th>\n",
       "      <th>anchor_frac</th>\n",
       "      <th>target_frac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adaptive technology</td>\n",
       "      <td>653.0</td>\n",
       "      <td>688498.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>assistive technology</td>\n",
       "      <td>653.0</td>\n",
       "      <td>688498.0</td>\n",
       "      <td>133</td>\n",
       "      <td>0.985185</td>\n",
       "      <td>0.452381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adaptive Design</td>\n",
       "      <td>653.0</td>\n",
       "      <td>688498.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.006803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>assistive device</td>\n",
       "      <td>653.0</td>\n",
       "      <td>688498.0</td>\n",
       "      <td>14</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.047619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>assistance</td>\n",
       "      <td>653.0</td>\n",
       "      <td>688498.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.006803</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            anchor_text  target_page_id  target_wikidata_numeric_id  \\\n",
       "0   Adaptive technology           653.0                    688498.0   \n",
       "1  assistive technology           653.0                    688498.0   \n",
       "2       Adaptive Design           653.0                    688498.0   \n",
       "3      assistive device           653.0                    688498.0   \n",
       "4            assistance           653.0                    688498.0   \n",
       "\n",
       "   anchor_target_count  anchor_frac  target_frac  \n",
       "0                    4     1.000000     0.013605  \n",
       "1                  133     0.985185     0.452381  \n",
       "2                    2     1.000000     0.006803  \n",
       "3                   14     1.000000     0.047619  \n",
       "4                    2     0.100000     0.006803  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchors = pd.read_csv('../data/raw/enwiki_20190801.k_raw_anchors.csv')\n",
    "anchors.dropna(inplace=True)\n",
    "anchors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchors['anchor_text_processed'] = anchors['anchor_text'].apply(lambda text: preprocess(text))\n",
    "#Drop any duplicates after processing anchor text\n",
    "anchors = anchors.drop_duplicates(subset = ['target_wikidata_numeric_id', 'anchor_text_processed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anchor_text</th>\n",
       "      <th>target_page_id</th>\n",
       "      <th>target_wikidata_numeric_id</th>\n",
       "      <th>anchor_target_count</th>\n",
       "      <th>anchor_frac</th>\n",
       "      <th>target_frac</th>\n",
       "      <th>anchor_text_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2875654</th>\n",
       "      <td>trump</td>\n",
       "      <td>6509278.0</td>\n",
       "      <td>727407.0</td>\n",
       "      <td>108</td>\n",
       "      <td>0.955752</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2559162</th>\n",
       "      <td>Trump</td>\n",
       "      <td>4848272.0</td>\n",
       "      <td>22686.0</td>\n",
       "      <td>249</td>\n",
       "      <td>0.803226</td>\n",
       "      <td>0.023828</td>\n",
       "      <td>trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871741</th>\n",
       "      <td>Trump</td>\n",
       "      <td>489947.0</td>\n",
       "      <td>7847760.0</td>\n",
       "      <td>24</td>\n",
       "      <td>0.077419</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6902014</th>\n",
       "      <td>Trump</td>\n",
       "      <td>56815814.0</td>\n",
       "      <td>35995833.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6703512</th>\n",
       "      <td>Trump</td>\n",
       "      <td>52231341.0</td>\n",
       "      <td>27809653.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.025806</td>\n",
       "      <td>0.009009</td>\n",
       "      <td>trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008974</th>\n",
       "      <td>Trump</td>\n",
       "      <td>640713.0</td>\n",
       "      <td>5634699.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.012903</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2924453</th>\n",
       "      <td>Trump</td>\n",
       "      <td>6808851.0</td>\n",
       "      <td>3999864.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.006452</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5919841</th>\n",
       "      <td>Trump</td>\n",
       "      <td>38316801.0</td>\n",
       "      <td>16944413.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.006452</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6703562</th>\n",
       "      <td>Trump</td>\n",
       "      <td>52231773.0</td>\n",
       "      <td>27811470.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.006452</td>\n",
       "      <td>0.035088</td>\n",
       "      <td>trump</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        anchor_text  target_page_id  target_wikidata_numeric_id  \\\n",
       "2875654       trump       6509278.0                    727407.0   \n",
       "2559162       Trump       4848272.0                     22686.0   \n",
       "871741        Trump        489947.0                   7847760.0   \n",
       "6902014       Trump      56815814.0                  35995833.0   \n",
       "6703512       Trump      52231341.0                  27809653.0   \n",
       "1008974       Trump        640713.0                   5634699.0   \n",
       "2924453       Trump       6808851.0                   3999864.0   \n",
       "5919841       Trump      38316801.0                  16944413.0   \n",
       "6703562       Trump      52231773.0                  27811470.0   \n",
       "\n",
       "         anchor_target_count  anchor_frac  target_frac anchor_text_processed  \n",
       "2875654                  108     0.955752     0.540000                 trump  \n",
       "2559162                  249     0.803226     0.023828                 trump  \n",
       "871741                    24     0.077419     0.888889                 trump  \n",
       "6902014                   10     0.032258     1.000000                 trump  \n",
       "6703512                    8     0.025806     0.009009                 trump  \n",
       "1008974                    4     0.012903     0.666667                 trump  \n",
       "2924453                    2     0.006452     0.095238                 trump  \n",
       "5919841                    2     0.006452     0.333333                 trump  \n",
       "6703562                    2     0.006452     0.035088                 trump  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchors[anchors.anchor_text_processed == 'trump'].sort_values('anchor_frac', ascending = False).iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make dictionary of anchor text mapping to list of candidates, in descending order of anchor frac\n",
    "def get_anchor_candidates(x):\n",
    "    wikidata_id, anchor_frac = list(x['target_wikidata_numeric_id']), list(x['anchor_frac'])\n",
    "    candidates_list = [(wikidata_id[i], anchor_frac[i]) for i in range(len(x))]\n",
    "    candidates_list = sorted(candidates_list, key = lambda x: x[1], reverse = True)\n",
    "    return candidates_list\n",
    "\n",
    "anchors_grouped = anchors.groupby(['anchor_text_processed']).apply(get_anchor_candidates)\n",
    "anchors_grouped_dict = anchors_grouped.to_dict()\n",
    "with open('../data/candidate_selection/anchors_dict.pkl', 'wb') as f:\n",
    "    pickle.dump(anchors_grouped_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# anchors_grouped = anchors.groupby(['anchor_text_processed']).apply(get_anchor_candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# anchors_grouped_dict = anchors_grouped.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('../data/candidate_selection/anchors_dict.pkl', 'wb') as f:\n",
    "#     pickle.dump(anchors_grouped_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_candidates(entity, lsh_k, anchor_k):\n",
    "    #Get lsh_k candidates for entity from LSH and anchor_k candidates from anchor\n",
    "    entity = preprocess(entity)\n",
    "    anchors_candidates = anchors_grouped_dict[entity][:anchor_k]\n",
    "    anchors_candidates = [int(candidate[0]) for candidate in anchors_candidates]\n",
    "    lsh_candidates = predict(entity, top_wikidata, 128, lsh_k, forest).tolist()\n",
    "    return set(anchors_candidates + lsh_candidates)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{148,\n",
       " 8733,\n",
       " 43467,\n",
       " 82714,\n",
       " 82972,\n",
       " 130582,\n",
       " 130693,\n",
       " 473473,\n",
       " 619865,\n",
       " 713170,\n",
       " 756037,\n",
       " 770553,\n",
       " 851782,\n",
       " 1447741,\n",
       " 2451592,\n",
       " 5100121,\n",
       " 13426199}"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_candidates('china', 10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "capstone"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
