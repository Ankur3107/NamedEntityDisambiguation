{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict, Counter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk import word_tokenize\n",
    "from tqdm import tqdm\n",
    "import string\n",
    "from text_cleaning_functions import *\n",
    "import pickle \n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counter = defaultdict(lambda: 0, {})\n",
    "unicode_dict = get_unicode_dict()\n",
    "stoplist = stopwords.words('english') + list(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    return [word.lower() for word in word_tokenize(text) if word.lower() not in stoplist and not word.isdigit()]\n",
    "\n",
    "def update_word_counter(row):\n",
    "    words = preprocess(row)\n",
    "    for word in words:\n",
    "        word_counter[word] += 1\n",
    "        \n",
    "def replace_accents_fixed(row, unicode_dict):\n",
    "    if pd.isna(row):\n",
    "        return \"\"\n",
    "    else:\n",
    "        return replace_accents(row, unicode_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done replacing accents\n",
      "1106.7389302253723\n",
      "done replacing accents\n",
      "1105.7295877933502\n",
      "done replacing accents\n",
      "1102.3962733745575\n",
      "done replacing accents\n",
      "1112.406487941742\n",
      "done replacing accents\n",
      "1107.9391508102417\n",
      "done replacing accents\n",
      "1103.346455335617\n",
      "done replacing accents\n",
      "1110.977682352066\n",
      "done replacing accents\n",
      "1116.8484773635864\n",
      "done replacing accents\n",
      "1117.633111000061\n",
      "done replacing accents\n",
      "1112.000411272049\n",
      "done replacing accents\n",
      "1106.4941940307617\n",
      "done replacing accents\n",
      "1116.5472385883331\n",
      "done replacing accents\n",
      "1113.4465773105621\n",
      "done replacing accents\n",
      "1122.1570847034454\n",
      "done replacing accents\n",
      "1115.303544998169\n",
      "done replacing accents\n",
      "1110.44864320755\n",
      "done replacing accents\n",
      "1108.845039844513\n",
      "done replacing accents\n",
      "1114.3676717281342\n",
      "done replacing accents\n",
      "1115.32794713974\n",
      "done replacing accents\n",
      "1120.809470653534\n",
      "done replacing accents\n",
      "1106.1233072280884\n",
      "done replacing accents\n",
      "533.6614880561829\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for chunk in pd.read_csv('../data/raw/enwiki_20190801.k_plaintext.csv', usecols = ['section_text'], chunksize=10 ** 6):\n",
    "    start = time.time()\n",
    "    chunk['section_text_cleaned'] = chunk['section_text'].apply(lambda i: replace_accents_fixed(i, unicode_dict))\n",
    "    print(\"done replacing accents\")\n",
    "    chunk['section_text_cleaned'].apply(update_word_counter)\n",
    "    with open(\"../data/word2idx/{}.pkl\".format(i), \"wb\") as f:\n",
    "        pickle.dump(dict(word_counter), f)    \n",
    "    end = time.time()\n",
    "    print(end - start)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17252450"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55868"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counter['obama']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/word2idx/{}.pkl\".format(20), \"rb\") as f:\n",
    "    word_counter = pickle.load(f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17010099"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counter_counter = Counter(word_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "445879"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = word_counter_counter.most_common(500000)\n",
    "vocab = set([s[0].translate(str.maketrans('', '', string.punctuation)) for s in vocab \n",
    "             if len(s[0].translate(str.maketrans('', '', string.punctuation))) != 0])\n",
    "idx = range(2, len(vocab)+2)\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx = dict(zip(vocab, idx))\n",
    "word2idx['PAD'] = 0\n",
    "word2idx['UNKNOWN'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "445881"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/word2idx/word2idx.pkl\", \"wb\") as f:\n",
    "    pickle.dump(word2idx, f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "capstone"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
