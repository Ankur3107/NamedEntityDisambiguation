{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, f1_score, roc_auc_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('../data/sample_embedding_dataset_imbalanced.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[:, :-1]\n",
    "y_train = train[:, -1]\n",
    "X_test = test[:, :-1]\n",
    "y_test = test[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matteo/.local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "lr_classifier = LogisticRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8462400616440755"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_classifier.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114204, 1251)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_classifier = GradientBoostingClassifier().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8776108250732607"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_classifier.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18843473083254528"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8678505131168786"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred = gb_classifier.predict(X_test)\n",
    "gb_classifier.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5602051521156312"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.706150494328653"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_train_scaled = sc.fit_transform(X_train)\n",
    "X_test_scaled = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1102 10:26:48.615102 140143621642048 deprecation_wrapper.py:119] From /home/matteo/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1102 10:26:48.694573 140143621642048 deprecation_wrapper.py:119] From /home/matteo/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1102 10:26:48.697477 140143621642048 deprecation_wrapper.py:119] From /home/matteo/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W1102 10:26:48.711051 140143621642048 deprecation_wrapper.py:119] From /home/matteo/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W1102 10:26:48.717536 140143621642048 deprecation.py:506] From /home/matteo/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W1102 10:26:48.729372 140143621642048 deprecation_wrapper.py:119] From /home/matteo/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4115: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "W1102 10:26:48.754931 140143621642048 deprecation_wrapper.py:119] From /home/matteo/.local/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W1102 10:26:48.768875 140143621642048 deprecation.py:323] From /home/matteo/.conda/envs/capstone/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "mlp_classifier = Sequential()\n",
    "mlp_classifier.add(Dense(64, activation = 'relu', input_dim=X_train_scaled.shape[1]))\n",
    "mlp_classifier.add(Dropout(0.2))\n",
    "mlp_classifier.add(Dense(64, activation='relu', kernel_initializer='random_normal'))\n",
    "mlp_classifier.add(Dropout(0.2))\n",
    "mlp_classifier.add(Dense(1, activation='sigmoid', kernel_initializer='random_normal'))\n",
    "\n",
    "mlp_classifier.compile(optimizer ='adam',loss='binary_crossentropy', metrics =['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 68522 samples, validate on 17131 samples\n",
      "Epoch 1/100\n",
      "68522/68522 [==============================] - 1s 17us/step - loss: 0.4053 - acc: 0.8188 - val_loss: 0.3396 - val_acc: 0.8489\n",
      "Epoch 2/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.3345 - acc: 0.8535 - val_loss: 0.3204 - val_acc: 0.8584\n",
      "Epoch 3/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.3130 - acc: 0.8632 - val_loss: 0.3106 - val_acc: 0.8629\n",
      "Epoch 4/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.2978 - acc: 0.8716 - val_loss: 0.3009 - val_acc: 0.8695\n",
      "Epoch 5/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.2846 - acc: 0.8780 - val_loss: 0.2954 - val_acc: 0.8723\n",
      "Epoch 6/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.2734 - acc: 0.8843 - val_loss: 0.2898 - val_acc: 0.8769\n",
      "Epoch 7/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.2641 - acc: 0.8893 - val_loss: 0.2900 - val_acc: 0.8764\n",
      "Epoch 8/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.2544 - acc: 0.8930 - val_loss: 0.2809 - val_acc: 0.8825\n",
      "Epoch 9/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.2464 - acc: 0.8981 - val_loss: 0.2829 - val_acc: 0.8833\n",
      "Epoch 10/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.2372 - acc: 0.9014 - val_loss: 0.2785 - val_acc: 0.8849\n",
      "Epoch 11/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.2306 - acc: 0.9050 - val_loss: 0.2815 - val_acc: 0.8844\n",
      "Epoch 12/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.2237 - acc: 0.9080 - val_loss: 0.2756 - val_acc: 0.8858\n",
      "Epoch 13/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.2182 - acc: 0.9097 - val_loss: 0.2767 - val_acc: 0.8861\n",
      "Epoch 14/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.2133 - acc: 0.9129 - val_loss: 0.2744 - val_acc: 0.8872\n",
      "Epoch 15/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.2078 - acc: 0.9150 - val_loss: 0.2716 - val_acc: 0.8885\n",
      "Epoch 16/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.2024 - acc: 0.9173 - val_loss: 0.2832 - val_acc: 0.8893\n",
      "Epoch 17/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.2002 - acc: 0.9181 - val_loss: 0.2731 - val_acc: 0.8879\n",
      "Epoch 18/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.1951 - acc: 0.9217 - val_loss: 0.2762 - val_acc: 0.8885\n",
      "Epoch 19/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.1894 - acc: 0.9234 - val_loss: 0.2816 - val_acc: 0.8900\n",
      "Epoch 20/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.1874 - acc: 0.9242 - val_loss: 0.2832 - val_acc: 0.8897\n",
      "Epoch 21/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.1873 - acc: 0.9235 - val_loss: 0.2750 - val_acc: 0.8919\n",
      "Epoch 22/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.1797 - acc: 0.9269 - val_loss: 0.2837 - val_acc: 0.8911\n",
      "Epoch 23/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.1779 - acc: 0.9287 - val_loss: 0.2790 - val_acc: 0.8896\n",
      "Epoch 24/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.1753 - acc: 0.9291 - val_loss: 0.2845 - val_acc: 0.8918\n",
      "Epoch 25/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.1712 - acc: 0.9300 - val_loss: 0.2945 - val_acc: 0.8896\n",
      "Epoch 26/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.1704 - acc: 0.9322 - val_loss: 0.2861 - val_acc: 0.8914\n",
      "Epoch 27/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.1661 - acc: 0.9329 - val_loss: 0.2926 - val_acc: 0.8905\n",
      "Epoch 28/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.1644 - acc: 0.9343 - val_loss: 0.2862 - val_acc: 0.8929\n",
      "Epoch 29/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.1609 - acc: 0.9346 - val_loss: 0.2839 - val_acc: 0.8916\n",
      "Epoch 30/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.1582 - acc: 0.9356 - val_loss: 0.2831 - val_acc: 0.8948\n",
      "Epoch 31/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.1569 - acc: 0.9375 - val_loss: 0.2879 - val_acc: 0.8947\n",
      "Epoch 32/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.1551 - acc: 0.9371 - val_loss: 0.2907 - val_acc: 0.8929\n",
      "Epoch 33/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.1534 - acc: 0.9382 - val_loss: 0.2907 - val_acc: 0.8932\n",
      "Epoch 34/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.1508 - acc: 0.9404 - val_loss: 0.2976 - val_acc: 0.8918\n",
      "Epoch 35/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.1530 - acc: 0.9385 - val_loss: 0.2873 - val_acc: 0.8918\n",
      "Epoch 36/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.1486 - acc: 0.9420 - val_loss: 0.2905 - val_acc: 0.8932\n",
      "Epoch 37/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.1457 - acc: 0.9423 - val_loss: 0.3013 - val_acc: 0.8920\n",
      "Epoch 38/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.1444 - acc: 0.9422 - val_loss: 0.2922 - val_acc: 0.8930\n",
      "Epoch 39/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.1433 - acc: 0.9435 - val_loss: 0.3006 - val_acc: 0.8923\n",
      "Epoch 40/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.1405 - acc: 0.9443 - val_loss: 0.3059 - val_acc: 0.8912\n",
      "Epoch 41/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.1414 - acc: 0.9443 - val_loss: 0.3027 - val_acc: 0.8915\n",
      "Epoch 42/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.1386 - acc: 0.9445 - val_loss: 0.3136 - val_acc: 0.8915\n",
      "Epoch 43/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.1378 - acc: 0.9447 - val_loss: 0.3073 - val_acc: 0.8914\n",
      "Epoch 44/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.1354 - acc: 0.9465 - val_loss: 0.3166 - val_acc: 0.8898\n",
      "Epoch 45/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.1344 - acc: 0.9469 - val_loss: 0.3100 - val_acc: 0.8921\n",
      "Epoch 46/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.1338 - acc: 0.9467 - val_loss: 0.3129 - val_acc: 0.8916\n",
      "Epoch 47/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.1331 - acc: 0.9475 - val_loss: 0.3168 - val_acc: 0.8907\n",
      "Epoch 48/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.1322 - acc: 0.9471 - val_loss: 0.3253 - val_acc: 0.8918\n",
      "Epoch 49/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.1337 - acc: 0.9468 - val_loss: 0.3100 - val_acc: 0.8931\n",
      "Epoch 50/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.1297 - acc: 0.9488 - val_loss: 0.3234 - val_acc: 0.8920\n",
      "Epoch 51/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.1283 - acc: 0.9496 - val_loss: 0.3172 - val_acc: 0.8901\n",
      "Epoch 52/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.1292 - acc: 0.9484 - val_loss: 0.3138 - val_acc: 0.8928\n",
      "Epoch 53/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.1286 - acc: 0.9490 - val_loss: 0.3128 - val_acc: 0.8922\n",
      "Epoch 54/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.1244 - acc: 0.9510 - val_loss: 0.3178 - val_acc: 0.8936\n",
      "Epoch 55/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.1251 - acc: 0.9503 - val_loss: 0.3132 - val_acc: 0.8930\n",
      "Epoch 56/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.1259 - acc: 0.9503 - val_loss: 0.3219 - val_acc: 0.8920\n",
      "Epoch 57/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.1233 - acc: 0.9517 - val_loss: 0.3258 - val_acc: 0.8933\n",
      "Epoch 58/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.1218 - acc: 0.9518 - val_loss: 0.3326 - val_acc: 0.8921\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.1202 - acc: 0.9525 - val_loss: 0.3396 - val_acc: 0.8930\n",
      "Epoch 60/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.1185 - acc: 0.9528 - val_loss: 0.3377 - val_acc: 0.8920\n",
      "Epoch 61/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.1199 - acc: 0.9529 - val_loss: 0.3273 - val_acc: 0.8916\n",
      "Epoch 62/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.1181 - acc: 0.9524 - val_loss: 0.3366 - val_acc: 0.8927\n",
      "Epoch 63/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.1183 - acc: 0.9535 - val_loss: 0.3537 - val_acc: 0.8922\n",
      "Epoch 64/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.1189 - acc: 0.9528 - val_loss: 0.3410 - val_acc: 0.8925\n",
      "Epoch 65/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.1169 - acc: 0.9539 - val_loss: 0.3340 - val_acc: 0.8911\n",
      "Epoch 66/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.1131 - acc: 0.9558 - val_loss: 0.3526 - val_acc: 0.8918\n",
      "Epoch 67/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.1146 - acc: 0.9550 - val_loss: 0.3399 - val_acc: 0.8937\n",
      "Epoch 68/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.1148 - acc: 0.9545 - val_loss: 0.3394 - val_acc: 0.8921\n",
      "Epoch 69/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.1128 - acc: 0.9563 - val_loss: 0.3400 - val_acc: 0.8909\n",
      "Epoch 70/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.1134 - acc: 0.9552 - val_loss: 0.3338 - val_acc: 0.8930\n",
      "Epoch 71/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.1125 - acc: 0.9564 - val_loss: 0.3454 - val_acc: 0.8918\n",
      "Epoch 72/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.1128 - acc: 0.9566 - val_loss: 0.3460 - val_acc: 0.8917\n",
      "Epoch 73/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.1094 - acc: 0.9579 - val_loss: 0.3397 - val_acc: 0.8911\n",
      "Epoch 74/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.1090 - acc: 0.9577 - val_loss: 0.3414 - val_acc: 0.8924\n",
      "Epoch 75/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.1110 - acc: 0.9561 - val_loss: 0.3386 - val_acc: 0.8925\n",
      "Epoch 76/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.1102 - acc: 0.9567 - val_loss: 0.3438 - val_acc: 0.8921\n",
      "Epoch 77/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.1080 - acc: 0.9583 - val_loss: 0.3437 - val_acc: 0.8921\n",
      "Epoch 78/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.1086 - acc: 0.9576 - val_loss: 0.3483 - val_acc: 0.8915\n",
      "Epoch 79/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.1083 - acc: 0.9575 - val_loss: 0.3521 - val_acc: 0.8925\n",
      "Epoch 80/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.1069 - acc: 0.9582 - val_loss: 0.3412 - val_acc: 0.8931\n",
      "Epoch 81/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.1056 - acc: 0.9596 - val_loss: 0.3500 - val_acc: 0.8935\n",
      "Epoch 82/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.1024 - acc: 0.9603 - val_loss: 0.3522 - val_acc: 0.8931\n",
      "Epoch 83/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.1072 - acc: 0.9581 - val_loss: 0.3444 - val_acc: 0.8933\n",
      "Epoch 84/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.1037 - acc: 0.9604 - val_loss: 0.3565 - val_acc: 0.8906\n",
      "Epoch 85/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.1047 - acc: 0.9595 - val_loss: 0.3580 - val_acc: 0.8925\n",
      "Epoch 86/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.1024 - acc: 0.9610 - val_loss: 0.3527 - val_acc: 0.8921\n",
      "Epoch 87/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.1030 - acc: 0.9595 - val_loss: 0.3724 - val_acc: 0.8901\n",
      "Epoch 88/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.1020 - acc: 0.9605 - val_loss: 0.3740 - val_acc: 0.8902\n",
      "Epoch 89/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.1025 - acc: 0.9609 - val_loss: 0.3642 - val_acc: 0.8903\n",
      "Epoch 90/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.1024 - acc: 0.9601 - val_loss: 0.3562 - val_acc: 0.8924\n",
      "Epoch 91/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.1006 - acc: 0.9600 - val_loss: 0.3595 - val_acc: 0.8918\n",
      "Epoch 92/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.0992 - acc: 0.9609 - val_loss: 0.3593 - val_acc: 0.8915\n",
      "Epoch 93/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.0996 - acc: 0.9611 - val_loss: 0.3631 - val_acc: 0.8925\n",
      "Epoch 94/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.1005 - acc: 0.9602 - val_loss: 0.3583 - val_acc: 0.8926\n",
      "Epoch 95/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.0973 - acc: 0.9626 - val_loss: 0.3722 - val_acc: 0.8896\n",
      "Epoch 96/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.0981 - acc: 0.9619 - val_loss: 0.3755 - val_acc: 0.8898\n",
      "Epoch 97/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.0993 - acc: 0.9615 - val_loss: 0.3767 - val_acc: 0.8892\n",
      "Epoch 98/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.0990 - acc: 0.9616 - val_loss: 0.3684 - val_acc: 0.8898\n",
      "Epoch 99/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.0963 - acc: 0.9625 - val_loss: 0.3757 - val_acc: 0.8906\n",
      "Epoch 100/100\n",
      "68522/68522 [==============================] - 1s 11us/step - loss: 0.0958 - acc: 0.9624 - val_loss: 0.3845 - val_acc: 0.8910\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7539c05990>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_classifier.fit(X_train_scaled, y_train, batch_size = 256, epochs = 100, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28551/28551 [==============================] - 0s 10us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4127206111816173, 0.888515288433316]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred = mlp_classifier.predict(X_test_scaled)\n",
    "mlp_classifier.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, np.where(y_test_pred > 0.5, 1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[22259,   912],\n",
       "       [ 2271,  3109]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6614189979789384"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, np.where(y_test_pred > 0.5, 1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9100808575454609"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "#     classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "#     print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "#     fig.tight_layout()\n",
    "    return ax\n",
    "\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plot_confusion_matrix(y_test, np.where(y_test_pred > 0.5, 1, 0), classes=[0, 1], normalize = True,\n",
    "                     );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "capstone"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
